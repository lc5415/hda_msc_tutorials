---
title: "Decision Trees"
author: "Jonathan Ish-Horowicz"
date: "18/02/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this tutorial, we will be looking at implementing the Decision Tree tools that are avaiable in R package `rpart`. In particular we will be looking applying a simple decision tree, using the Gini Index, to the Iris dataset, followed by a more complex dataset. Both are classification problems.

```{r}
# Load the iris dataset
data(iris)
```

As an example, we call the function `rpart::rpart`. This has several options that we can change, but for now, let's see what the default tree looks like for the full iris dataset.

Create a tree then plot it using `rpart.plot::rpart.plot`:


```{r}
library(rpart)
library(rpart.plot)

# your code here
```

By default `rpart` uses the Gini impurity in the splitting criterion. We can choose to use the entropy (also called information gain) instead using the `parms` argument.

Construct a tree from the `iris` data using entropy to split. Then compare the resulting tree with the tree constructed using Gini impurity.

```{r}
# your code here
```
In this case the two trees are the same.

For more hyperparameters we use the `rpart::rpart.control` function, which we pass to `rpart::rpart` using the `control` argument. Use it to build a deeper tree (hint: you will need to alter the `minbucket`, `cp` and `maxdepth` arugments to `rpart::rpart.control` - check their meaning in the documentation).

```{r}
# your code here
```

The `maxdepth` setting prunes the full tree seen above until the longest path in the tree is equal to `maxdepth`. Pruning simplifies the model by removing roots that lead to relatively low information gains. This in turn makes the model more interpretable to humans, and also prevents overfitting.

Lets look at how the `max_depth` affects the accuracy of the model. Start by splitting the data into train and test sets. Use the default `rpart::rpart` arguments to begin with and evaluate the accuracy on the test set.

```{r}
# your code here
```

Now try the same with a deeper tree. Compare the test accuracies.

```{r}
# your code here
```

The test accuracies are different (yours may be higher or lower, depending on the random seed).

We can now do a more systematic hyperparameter search using a grid search. Perform a grid search for the hyperparemer `maxdepth` values using the `caret` package, which is ubiquitos for machine learning in R. Use k-fold cross-validation (you should choose a sensible value of k given the dataset size).

Hint: start off by calling `caret::trainControl` then use `caret::train` with `method='rpart2'`. There are many good `caret` tutorials online. Control the parameter combinations you want to try using the `tunegrid` argument to `caret::train`.

```{r}
library(caret)

# your code here
```

# PIMA-INDIAN Dataset

Now lets do the same analysis for a much more complicated dataset. Details about this dataset can be found [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database). As a summary, it contains 768 data points with 8 features and a single binary target variable.

```{r}
# Load pima dataset
col.names = c('pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label')

pima <- read.csv("diabetes.csv", header=FALSE, col.names=col.names)
pima$label <- as.factor(pima$label)
head(pima)
```

Now train a model on the whole PIMA dataset:

```{r}
# your code here
```

Is this the best model we can obtain? Use `caret::train` again to choose a model using k-fold cross-validation.

```{r}
# your code here
```

Now plot the best model according to the cross-validation.

Hint: objects returned by `caret::train` have a `finalModel` field.

```{r}
# your code here
```

