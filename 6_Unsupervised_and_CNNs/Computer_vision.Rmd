---
title: "Computer Vision"
author: "Jonathan Ish-Horowicz"
date: "02/03/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Keras Installation

Using Keras in R is a bit more complicated than in Python, since the R version is just a wrapper for the Python version anyway.

```{r, eval=FALSE}
# Only run if you haven't already installed Keras for R
install.packages("devtools")
devtools::install_github("rstudio/keras")
library(keras)
install_keras()
```

If you have successfully installed Keras then continue. If you are having a lot of problems with the installation then consider switching to Python for deep learning.

```{r}
library(keras)
```

# Logistic regression for MNIST digits

We start by loading the MNIST data.

```{r}
# Load data
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y

x_train <- x_train/255.0
x_test <- x_test/255.0

y_train <- to_categorical(y_train, num_classes=10)
y_test <- to_categorical(y_test, num_classes=10)
```

There are 60,000 training and 10,000 test images. Each image is 18x18 pixels. We have also one-hot encoded the labels.

We can show display some of the images before we start. This is always a good idea before starting any computer vision task.

```{r}
image.idx <- sample(1:dim(x_train)[[1]], size=1)
image(x_train[image.idx,,], useRaster=TRUE, axes=FALSE, main=paste("digit:", y_train[image.idx]))
```

A neural network with no hidden layers and a softmax activation function is just multinomial logistic regression. 

Logistic regression works on vectors, while MNIST digits are images. So we have to flatten the arrays containing the images to make them into vectors (this is part of the reason convolutional neural networks outperform logistic regression - they retain the spatial information of the pixels).

```{r}
flatten.array <- function(arr) {
  return(t(apply(arr, 1, c)))
}
x_train_flat <- flatten.array(x_train)
x_test_flat <- flatten.array(x_test)
```

Construct a logistic regression model to classify MNIST digits using keras.

```{r}
# your code here
model <- keras_model_sequential()
model %>%
  layer_dense(units=10, activation='softmax', input_shape=c(784))
```

Now compile the model.

```{r}
model %>% compile(
  optimizer = 'adadelta',
  loss = 'categorical_crossentropy',
  metrics = list('accuracy')
)
```

Now fit the model.

```{r}
model %>% fit(
  x_train_flat,
  y_train,
  epochs=10,
  batch_size=32
)
```

Then evaluate on the test set:

```{r}
score <- model %>% evaluate(x_test_flat, y_test)
print(score)
```

We can achieve a quite high test accuracy even with this simple model, so this is quite a simple problem.

# Convolutional Neural Network for MNIST digits

Now we will build a small convolutional neural network.

Add more layers to the network and try to improve on the test accuracy you achieved with logistic regression. Put convolutional layers at the start of the network then use dense layers further in. Use the same procedure as when building the previous model: (i) define the layers, (ii) compile the model and (iii) fit the model. Then evaluate on the test set.

```{r}
# your code here

# hint: use layer_conv_2d() and layer_dense()
```